{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 코인으로 마통갚기 강화학습 (Deep Q Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Motivation : 마이너스 통장에 대출이 있는데, 한달에 생활비를 제외하면 최대 갚을 수 있는 돈이 정해져 있음. 이중에 일부를 대출상환에 쓰고 일부는 주식 또는 코인에 투자하려고 함. 이 경우, 이자를 적게 내기 위한 가장 적합한 상환 전략은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "from itertools import product\n",
    "from collections import deque\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "State space : 대출 잔액, 코인 계좌 잔액, (time t)\n",
    "- 최초 대출금액은 5천만원. 1만원 단위로 갚는 경우로 가정.\n",
    "- 그리고 코인계좌 잔액 요렇게 2개가 될듯 함. \n",
    "- 이자랑 코인 수익 만원단위까지 계산 넣으려면 State Space 는 만원 단위로 설정해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "state_space = np.arange(0, 5000, 1)\n",
    "print(len(state_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Action space : 대출 상환금액, 코인 인출 금액\n",
    "- 매달 생활비 빼고 이자 상환할 수 있는 금액은 60만원 인데, 이중에서 얼마는 코인에 투자하고 얼마는 대출을 갚으려고 함. 코인에 투자한 금액은 다음달에 확률적으로 오를수도 있고 떨어질 수도 있어.\n",
    "- 코인 계좌에서 얼마를 인출할 것인가? (0%~100% 로 비율로 인출하는 것으로 가정)\n",
    "- 만원단위로 설정할지, 10만원단위로 할지 -> 계산 편의상 10만원부터 해보고 나중에 1만원 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 60)\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "debt_repay = np.arange(0, 60, 1)\n",
    "coin_withdrawal = np.arange(0, 100, 1)\n",
    "\n",
    "# 2가지 액션의 조합으로 액션 설명하고자 함. - 얼마나 적급할거냐, coint에서 얼마나 뺄거냐\n",
    "xx, yy = np.meshgrid(debt_repay, coin_withdrawal)\n",
    "print(xx.shape)\n",
    "\n",
    "action_space = list(product(debt_repay, coin_withdrawal))\n",
    "print(len(action_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reward space : 매달 내는 이자 상환액 (대출금리 * 대출잔액)\n",
    "- 3.75 고정금리 가정\n",
    "- 변동금리 가정 -> 현실하고 유사하게 만들려면 고민 필요함. 에피소드 생성시점에 에피소드 길이만큼 만들어서 reward 생성해야 할듯함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.       0.003125 0.00625  0.009375 0.0125  ] ... [15.609375 15.6125   15.615625 15.61875  15.621875]\n"
     ]
    }
   ],
   "source": [
    "# 고정금리 경우\n",
    "reward_space = state_space * 3.75e-2 / 12\n",
    "print(reward_space[:5], \"...\", reward_space[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Transition Matrix : 다음달 남은 대출잔액으로 옮겨갈 확률(?)\n",
    "\n",
    "- P 는 그리기 어려워서 아래 설명. 에피소드 발생 시점에 나와...\n",
    "- 다음달 잔액 계산식:\n",
    "\n",
    "\\begin{align}\n",
    "대출잔액_{t+1} &= 대출잔액_{t} - 대출원금상환액_{t} \\nonumber \\\\\n",
    "대출원금상환액_t &= 상환금액(0to60만원)_t + 코인수익_t * 코인인출비율(0to100) - 이번달이자_t \\nonumber \\\\\n",
    "코인수익_t &= (지난달코인잔액_{t-1} + 지난달코인납입액_{t-1}) * 지난달 코인변동_{t-1} \\nonumber \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Episode generator or Environment: 주어진 기간(10년=120t) 에피소드 동안 s, a, r, s+1 생성하는 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class DebtRepayer(object):\n",
    "    def __init__(self, start_debt, duration=120, interest_rate=3.75, round=0) -> None:\n",
    "        self.start_debt = start_debt\n",
    "        self.current_debt = start_debt\n",
    "        self.duration = duration\n",
    "        self.t = 0\n",
    "        self.coin_balance = 0\n",
    "        self.interest_rate = interest_rate / 100 # 은행 대출 이자 - 고정금리 가정\n",
    "        self.round = round\n",
    "\n",
    "        # action_space grid\n",
    "        self.repay_grid, self.withdraw_grid = np.meshgrid(np.arange(10, 70, 10), np.arange(0, 110, 10))\n",
    "\n",
    "        # history\n",
    "        self.history = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_debt = self.start_debt\n",
    "        self.coin_balance = 0\n",
    "        self.history = []\n",
    "        self.t = 0\n",
    "\n",
    "    def get_one_episode(self, policy):\n",
    "        for action in policy:\n",
    "            sample = self.forward_one_month((action[0], action[1]))\n",
    "            if sample[3][1] == 0: break\n",
    "            if sample[3][0] > 120: break\n",
    "\n",
    "        return self.history\n",
    "            \n",
    "    def forward_one_month(self, action: tuple):\n",
    "        past_state = (self.t, self.current_debt, self.coin_balance)\n",
    "        repay_amount = action[0]\n",
    "        withdraw_pct = action[1] / 100\n",
    "        interest_amount = round(self.current_debt * self.interest_rate / 12, self.round)\n",
    "\n",
    "        repay_amount = min(60 - interest_amount, repay_amount) # 은행 이자 제외하고 남은 금액에서만 값을 수 있음.\n",
    "        coin_input = 60 - repay_amount - interest_amount\n",
    "        \n",
    "        withdrawed_coin = self.get_coin_balance(coin_input, withdraw_pct)\n",
    "        total_repay_amount = repay_amount + withdrawed_coin\n",
    "\n",
    "        self.current_debt -= total_repay_amount\n",
    "        if self.current_debt <= 0:\n",
    "            self.current_debt = 0\n",
    "            done = 0\n",
    "        else:\n",
    "            done = 1\n",
    "        self.t += 1\n",
    "        prime_state = (self.t, self.current_debt, self.coin_balance)\n",
    "\n",
    "        sample = (past_state, action, interest_amount, prime_state, done)\n",
    "        self.history.append(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    # 다음달 코인 잔액 및 인출액 생성기 - \n",
    "    def get_coin_balance(self, current_input, withdraw_pct):\n",
    "        #상승 or 하락으로 정해서 beta 분포로 변동 설정함\n",
    "        if np.random.rand() >= 0.5:\n",
    "            change_rate = np.random.beta(a=1.5, b=4)\n",
    "        else:\n",
    "            change_rate = -(np.random.beta(a=1.25, b=8.7))\n",
    "        # 코인 잔액 업데이트하고 인출액 반환 - FIXME 순서확인, 마이너스 안나게 input 값 고려 \n",
    "        withdrawal_amount = round(self.coin_balance * withdraw_pct, self.round)\n",
    "        temp_balance = self.coin_balance - withdrawal_amount   # 당월 인출\n",
    "        temp_balance += current_input # 당월 입금\n",
    "        self.coin_balance = round(temp_balance + (temp_balance * change_rate), self.round)\n",
    "        if self.coin_balance < 0: self.coin_balance = 0\n",
    "\n",
    "        return withdrawal_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 5000, 0), (1, 4), 15.625, (1, 4999.0, 27.6795), 1),\n",
       " ((1, 4999.0, 27.6795), (3, 4), 15.6219, (2, 4994.8928, 74.465), 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = DebtRepayer(start_debt=5000, round=4)\n",
    "d.forward_one_month(action=(1, 4))\n",
    "d.forward_one_month(action=(3, 4))\n",
    "d.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\"A class for store episodes\"\"\"\n",
    "    def __init__(self, capacity) -> None:\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def get_sample(self, n):\n",
    "        batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for transition in batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        sample = (\n",
    "            torch.tensor(s_lst, dtype=torch.float),\n",
    "            a_lst,\n",
    "            torch.tensor(r_lst, dtype=torch.float),\n",
    "            torch.tensor(s_prime_lst, dtype=torch.float),\n",
    "            torch.tensor(done_mask_lst, dtype=torch.float),\n",
    "        )\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.qnet = nn.Sequential(\n",
    "            nn.Linear(3, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 60),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.qnet(x)\n",
    "\n",
    "    def sample_action(self, obs, eps):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.Tensor(obs)\n",
    "        out = self.forward(obs)\n",
    "        if random.random() < eps:\n",
    "            return random.randint(0, 59)\n",
    "        else:\n",
    "            return out.argmax().item()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "gamma = 1\n",
    "buffer_limit = 5000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train(q, q_target, buffer, opt, gamma, batch_size):\n",
    "    s, a, r, s_prime, done_mask = buffer.get_sample(batch_size)\n",
    "\n",
    "    q_out = q(s)\n",
    "    action_idx = torch.tensor([action_space.index(i) for i in a], dtype=torch.int64).unsqueeze(1)\n",
    "    q_a = q_out.gather(1, action_idx)\n",
    "    max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "    target = -r + gamma * max_q_prime * done_mask\n",
    "    loss = F.smooth_l1_loss(q_a, target)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def main(epoch: int):\n",
    "    # set envs\n",
    "    env = DebtRepayer(start_debt=5000, round=4)\n",
    "    buffer = ReplayBuffer(buffer_limit)\n",
    "\n",
    "    # set model\n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    opt = optim.AdamW(q.parameters(), lr=lr)\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    \n",
    "    # set training loop\n",
    "    G = 0\n",
    "    eps = 1\n",
    "    pbar = tqdm(range(epoch), desc=\"Deep Q net trainin : \", miniters=10)\n",
    "    for epi in pbar:\n",
    "        eps = max(eps * 0.9997, 0.001)\n",
    "        env.reset()\n",
    "        s = [env.t, env.start_debt, env.coin_balance]\n",
    "\n",
    "        # put samples until episode ends\n",
    "        flag = False\n",
    "        while not flag: \n",
    "            a = q.sample_action(s, eps)\n",
    "            sample = env.forward_one_month(action_space[a])\n",
    "            buffer.put((sample))\n",
    "            s = sample[3]\n",
    "            G += sample[2]\n",
    "            if s[1] == 0: break\n",
    "            if s[0] >= 120: break\n",
    "\n",
    "        # training when buffer got enough samples ten backward per one loop\n",
    "        if len(buffer) > 2000:\n",
    "            for _ in range(10):\n",
    "                train(q, q_target, buffer, opt, gamma, batch_size)\n",
    "\n",
    "        # q_target copy trained q every 20 loop\n",
    "        if epi % 20 == 0 and epi != 0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "\n",
    "            q_1a = action_space[q(torch.Tensor((0, 5000, 0))).argmax().item()]\n",
    "            pbar.set_postfix_str(\"n_episode : {}, Q1 : {}, interest_amount : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(epi, q_1a, G, len(buffer), eps))\n",
    "\n",
    "            G = 0\n",
    "    \n",
    "    print(\"Training done!!\")\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deep Q net trainin : 100%|█| 10000/10000 [03:02<00:00, 54.66it/s, n_episode : 9980, Q1 : (0, 16), interest_amount : 18060.9, n_buffer : 5000, eps : 0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = main(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "9647a49844672eb46cfa6f11b9cd6e23de5390f9773752bd69eef04b44300db2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
